{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5076,"status":"ok","timestamp":1688374966618,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"BePiqnqgrx6W"},"outputs":[],"source":["import os, glob\n","import logging\n","\n","from pprint import pprint\n","from tqdm import tqdm\n","import json\n","# import nltk\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# 에러 메세지만 로깅한다\n","tf.get_logger().setLevel(logging.ERROR)\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1688374967693,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"plwcoxBVrz2u"},"outputs":[],"source":["# The percentage of the dataset you want to split as train and test\n","TEST_SIZE = 0.1\n","\n","MAX_INPUT_LENGTH = 512  # Maximum length of the input to the Encoder\n","MIN_TARGET_LENGTH = 5  # Minimum length of the output by Decoder\n","MAX_TARGET_LENGTH = 128  # Maximum length of the output by Decoder\n","BATCH_SIZE = 8  # Batch-size for training our model\n","LEARNING_RATE = 2e-5  # Learning-rate for training our model\n","MAX_EPOCHS = 1  # Maximum number of epochs we will train the model for\n","\n","# HF model hub에서 가져올 모델 이름\n","MODEL_CHECKPOINT = \"psyche/KoT5-summarization\""]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5565,"status":"ok","timestamp":1688374979249,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"smCZnvrer3JE"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoConfig\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n","config = AutoConfig.from_pretrained(MODEL_CHECKPOINT)\n","config.vocab_size = tokenizer.vocab_size"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":436,"status":"ok","timestamp":1688374979668,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"0DgiuWXpr-x7"},"outputs":[],"source":["from google.colab import auth\n","auth.authenticate_user()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59213,"status":"ok","timestamp":1688375038878,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"ewy8zQzlsH1x","outputId":"c035fecf-e9ff-48ed-92a6-2f13e9861adf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Available number of replicas: 8\n"]}],"source":["tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","\n","tf.config.experimental_connect_to_cluster(tpu)\n","tf.tpu.experimental.initialize_tpu_system(tpu)\n","\n","strategy = tf.distribute.TPUStrategy(tpu)\n","\n","print(f\"Available number of replicas: {strategy.num_replicas_in_sync}\")"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":275,"status":"ok","timestamp":1688375070311,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"fcAJi5DX3-_W"},"outputs":[],"source":["\n","def decode_fn(example):\n","    features = {\n","        \"input_ids\": tf.io.FixedLenFeature(\n","            dtype=tf.int64, shape=(MAX_INPUT_LENGTH,)\n","        ),\n","        \"attention_mask\": tf.io.FixedLenFeature(\n","            dtype=tf.int64, shape=(MAX_INPUT_LENGTH,)\n","        ),\n","        'labels': tf.io.FixedLenFeature(\n","            dtype=tf.int64, shape=(MAX_INPUT_LENGTH,)\n","        )\n","    }\n","    return tf.io.parse_single_example(example, features)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1688375070744,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"g0xLAoq3sAQn"},"outputs":[],"source":["def _parse_function(example_proto):\n","\n","    name_to_features = {'input_ids': tf.io.FixedLenFeature([], tf.string),\n","                        'attention_mask':tf.io.FixedLenFeature([], tf.string),\n","                        'labels':tf.io.FixedLenFeature([], tf.string)}\n","\n","    example = tf.io.parse_single_example(example_proto, name_to_features)\n","\n","    for name in list(example.keys()):\n","        t = example[name]\n","        example[name] = tf.io.parse_tensor(t, out_type=tf.int64)\n","\n","    return example"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":295,"status":"ok","timestamp":1688375073731,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"HoNSaEFisB67"},"outputs":[],"source":["def load_tfrecord_dataset(tfrecord_name, batch_size, shuffle=True, buffer_size=10240):\n","    \"\"\"load dataset from tfrecord\"\"\"\n","    raw_dataset = tf.data.TFRecordDataset(tfrecord_name)\n","    raw_dataset = raw_dataset.repeat()\n","\n","    if shuffle:\n","        raw_dataset = raw_dataset.shuffle(buffer_size=buffer_size)\n","\n","    dataset = raw_dataset.map(\n","        _parse_function,\n","        num_parallel_calls=tf.data.experimental.AUTOTUNE\n","    )\n","\n","\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","    return dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":435,"status":"ok","timestamp":1688375085126,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"ujI8T_XXsDgv","outputId":"c7d1b955-97b2-427f-aca4-a148f52c433c"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n"]}],"source":["tfr_path = 'gs://ohsori-tfrecord/tfrecord/KoT5_train.tfrecord'\n","train = load_tfrecord_dataset(tfr_path, batch_size=BATCH_SIZE, shuffle=False)\n","print(type(train))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1688375085548,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"uHNiXbCpsEsg","outputId":"808036e1-a0ef-44d1-f9f5-03fdc4d7a0bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n"]}],"source":["tfr_path = 'gs://ohsori-tfrecord/tfrecord/KoT5_test.tfrecord'\n","test = load_tfrecord_dataset(tfr_path, batch_size=BATCH_SIZE, shuffle=False)\n","print(type(test))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1688375085879,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"0mW7qDltsGQ-","outputId":"5d23afad-d176-4b89-bfbd-a1be4d404658"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n"]}],"source":["tfr_path = 'gs://ohsori-tfrecord/tfrecord/KoT5_gen.tfrecord'\n","gen = load_tfrecord_dataset(tfr_path, batch_size=BATCH_SIZE, shuffle=False)\n","print(type(gen))"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1688375088960,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"ZEyBd3dtxxbc","outputId":"5bb04971-79ef-4bc8-a232-02beab4d3265"},"outputs":[{"data":{"text/plain":["<_PrefetchDataset element_spec={'attention_mask': TensorSpec(shape=<unknown>, dtype=tf.int64, name=None), 'input_ids': TensorSpec(shape=<unknown>, dtype=tf.int64, name=None), 'labels': TensorSpec(shape=<unknown>, dtype=tf.int64, name=None)}>"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["train"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4402,"status":"ok","timestamp":1688375100196,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"NQ99VXpiuMUw","outputId":"9e830cb2-85df-4b83-d968-9f3a065a8722"},"outputs":[{"name":"stdout","output_type":"stream","text":["(1, 8, 512)\n"]}],"source":["first_batch = next(iter(train.batch(1)))\n","print(first_batch['input_ids'].shape)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1688375100196,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"-TAmrn61xv-4","outputId":"811ac3b6-9199-4f7c-8e31-21471915f537"},"outputs":[{"data":{"text/plain":["{'attention_mask': <tf.Tensor: shape=(1, 8, 512), dtype=int64, numpy=\n"," array([[[1, 1, 1, ..., 0, 0, 0],\n","         [1, 1, 1, ..., 0, 0, 0],\n","         [1, 1, 1, ..., 0, 0, 0],\n","         ...,\n","         [1, 1, 1, ..., 0, 0, 0],\n","         [1, 1, 1, ..., 0, 0, 0],\n","         [1, 1, 1, ..., 0, 0, 0]]])>,\n"," 'input_ids': <tf.Tensor: shape=(1, 8, 512), dtype=int64, numpy=\n"," array([[[16038, 26202, 18596, ...,     0,     0,     0],\n","         [16038, 26202,  8874, ...,     0,     0,     0],\n","         [16038, 26202,   438, ...,     0,     0,     0],\n","         ...,\n","         [16038, 26202, 25889, ...,     0,     0,     0],\n","         [16038, 26202,   601, ...,     0,     0,     0],\n","         [16038, 26202, 25889, ...,     0,     0,     0]]])>,\n"," 'labels': <tf.Tensor: shape=(1, 8, 39), dtype=int64, numpy=\n"," array([[[  504, 25938,    68,  3363,    61,  5457,   851,  5432,   172,\n","          14699,  6705,  6197,   100, 25965, 26074, 25905,   504, 26056,\n","          26402, 25894,  3975,   504, 25895, 16915,  5407, 25892,     1,\n","           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n","           -100,  -100,  -100],\n","         [ 6244,  7392, 26042,   949, 25911,  1388,  1083,  1444,   417,\n","          25910,   231,  2484, 10861,    25,   457,    43,  5249, 25899,\n","           1939,   283,  9414, 13101,    34,   339,   223, 25892,     1,\n","           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n","           -100,  -100,  -100],\n","         [    5,   784, 10035,    51,  5234,   246, 25953,  1051,  3738,\n","            137,  2462,  3864,  1160,     5,  7455,  2976,    47,  8708,\n","           1667,  2260,  1323,   435,   400,   253, 25892,     1,  -100,\n","           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n","           -100,  -100,  -100],\n","         [  218, 26274, 10264,   801, 26057, 13538,  5988,   945,  6839,\n","             56, 25991, 25908,  4941,     3,  1103,   323,    37, 26296,\n","            587,   260,  4133,  3216,   274, 25914,   121,  1034,     5,\n","          11142,  4175, 25903,    28, 26162, 15463,  1419,   110, 18139,\n","          17589, 25892,     1],\n","         [  931,    84,  4000, 25909, 26413, 25895,    44,    94, 25938,\n","             89, 18155,  7943,   179, 25912, 26931, 25896,  1477,  2757,\n","           9169, 25892,     1,  -100,  -100,  -100,  -100,  -100,  -100,\n","           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n","           -100,  -100,  -100],\n","         [  131, 25906,  9765,   638,   143,   630,   109, 27117, 25974,\n","            385, 26196,   761,   685,   385, 26196,   972,    67,   169,\n","             61,    39,  3875,  1738,   222,  3813, 22466,  6847, 15316,\n","             16,   315, 17730, 26114, 26083,    48, 25892,     1,  -100,\n","           -100,  -100,  -100],\n","         [   44,   969, 25894,  6163,  2106, 21945,  1562,  4078,   570,\n","           3485, 17642,   792,   159,   792, 20753,   555,   480,    45,\n","            462, 23052,  2091,   164,  1340, 25892,     1,  -100,  -100,\n","           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n","           -100,  -100,  -100],\n","         [  401, 11265,   538,  4535,   422,   254,  1156, 18497, 14799,\n","            565,  1705,  4279, 25892,     1,  -100,  -100,  -100,  -100,\n","           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n","           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n","           -100,  -100,  -100]]])>}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["first_batch"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2438,"status":"ok","timestamp":1688375112666,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"TasONR2DsKs5"},"outputs":[],"source":["import keras_nlp\n","\n","rouge_l = keras_nlp.metrics.RougeL()\n","\n","def metric_fn(eval_predictions):\n","    predictions, labels = eval_predictions\n","    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    for label in labels:\n","        label[label < 0] = tokenizer.pad_token_id  # Replace masked label tokens\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    result = rouge_l(decoded_labels, decoded_predictions)\n","    # We will print only the F1 score, you can use other aggregation metrics as well\n","    result = {\"RougeL\": result[\"f1_score\"]}\n","\n","    return result"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22882,"status":"ok","timestamp":1688375138073,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"ydWuHwuYsMqD","outputId":"e1fa92a1-1927-410f-a977-429ac5ae95ac"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFT5ForConditionalGeneration: ['encoder.embed_tokens.weight', 'lm_head.weight', 'decoder.embed_tokens.weight']\n","- This IS expected if you are initializing TFT5ForConditionalGeneration from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFT5ForConditionalGeneration from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"]}],"source":["from tensorflow.keras.backend import clear_session\n","from transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n","# 요약 task는 seq2seq task로 분류된다\n","\n","model = TFAutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT, from_pt=True)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1688375138074,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"BWj5jYvcsOBs","outputId":"6d9d6b7d-e47f-4cf0-af64-9ab5c9100f0c"},"outputs":[{"name":"stderr","output_type":"stream","text":["No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"]}],"source":["optimizer = keras.optimizers.AdamW(learning_rate=LEARNING_RATE)\n","model.compile(optimizer=optimizer) # loss 값은 내부적으로 처리하도록 설정"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":383,"status":"ok","timestamp":1688375155546,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"FPp2BDiotyrO"},"outputs":[],"source":["clear_session()"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1688375156039,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"bqoIIl06sPVy","outputId":"8c6127a4-cdbf-4582-a53f-0e9ee7f83c3b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"tft5_for_conditional_generation\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," shared (TFSharedEmbeddings)  multiple                 24674304  \n","                                                                 \n"," encoder (TFT5MainLayer)     multiple                  84954240  \n","                                                                 \n"," decoder (TFT5MainLayer)     multiple                  113275008 \n","                                                                 \n","=================================================================\n","Total params: 222,903,552\n","Trainable params: 222,903,552\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":5276,"status":"error","timestamp":1688375180907,"user":{"displayName":"강호준","userId":"11314168820420018931"},"user_tz":-540},"id":"2xPzE3f-sQz0","outputId":"fb2f738b-104a-4ed1-9e99-454878aa0e9b"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:root:No label_cols specified for KerasMetricCallback, assuming you want the 'labels' key.\n"]},{"ename":"OperatorNotAllowedInGraphError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-c38e292063af>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# For now we will use our test set as our validation_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1117, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    OperatorNotAllowedInGraphError: Exception encountered when calling layer 'tft5_for_conditional_generation' (type TFT5ForConditionalGeneration).\n    \n    in user code:\n    \n        File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1327, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 1372, in call  *\n            encoder_outputs = self.encoder(\n        File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        OperatorNotAllowedInGraphError: Exception encountered when calling layer 'encoder' (type TFT5MainLayer).\n        \n        in user code:\n        \n            File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1327, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 677, in call  *\n                batch_size, seq_length = input_shape\n        \n            OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n        \n        \n        Call arguments received by layer 'encoder' (type TFT5MainLayer):\n          • input_ids=tf.Tensor(shape=<unknown>, dtype=int64)\n          • attention_mask=tf.Tensor(shape=<unknown>, dtype=int64)\n          • encoder_hidden_states=None\n          • encoder_attention_mask=None\n          • inputs_embeds=None\n          • head_mask=None\n          • encoder_head_mask=None\n          • past_key_values=None\n          • use_cache=None\n          • output_attentions=False\n          • output_hidden_states=False\n          • return_dict=True\n          • training=True\n    \n    \n    Call arguments received by layer 'tft5_for_conditional_generation' (type TFT5ForConditionalGeneration):\n      • input_ids={'attention_mask': 'tf.Tensor(shape=<unknown>, dtype=int64)', 'input_ids': 'tf.Tensor(shape=<unknown>, dtype=int64)', 'labels': 'tf.Tensor(shape=<unknown>, dtype=int64)'}\n      • attention_mask=None\n      • decoder_input_ids=None\n      • decoder_attention_mask=None\n      • head_mask=None\n      • decoder_head_mask=None\n      • encoder_outputs=None\n      • past_key_values=None\n      • inputs_embeds=None\n      • decoder_inputs_embeds=None\n      • labels=None\n      • use_cache=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • training=True\n"]}],"source":["from transformers.keras_callbacks import KerasMetricCallback\n","from tensorflow.keras.backend import clear_session\n","\n","metric_callback = KerasMetricCallback(\n","    metric_fn, eval_dataset=gen, predict_with_generate=True\n",")\n","\n","callbacks = [metric_callback]\n","\n","\n","# For now we will use our test set as our validation_data\n","model.fit(\n","    train, validation_data=test,\n","    epochs=MAX_EPOCHS,\n","    callbacks=callbacks,\n","    steps_per_epoch=8640//BATCH_SIZE,\n","    validation_steps=960//BATCH_SIZE,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IebtKORnzGMS"},"outputs":[],"source":[]}],"metadata":{"accelerator":"TPU","colab":{"authorship_tag":"ABX9TyOr3uuIk6mGBD1nnPUMl5AK","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
